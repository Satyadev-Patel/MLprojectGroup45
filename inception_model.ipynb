{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 9,
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
   "id": "a8aa548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras import models\n",
    "from keras.models import Model\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 21,
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
   "id": "96c0065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24282 images belonging to 5 classes.\n",
      "Found 5937 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "img_rows = 48\n",
    "img_cols = 48\n",
    "batch_size = 32\n",
    "num_classes = 5\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=30,\n",
    "                shear_range=0.3,\n",
    "                zoom_range=0.3,\n",
    "                width_shift_range=0.4,\n",
    "                height_shift_range=0.4,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_data_dir,\n",
    "                color_mode='grayscale',\n",
    "                target_size=(48,48),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical',\n",
    "                shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                        validation_data_dir,\n",
    "                        color_mode='grayscale',\n",
    "                        target_size=(img_rows,img_cols),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='categorical',\n",
    "                        shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 7,
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
   "id": "a7702dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_x = 48\n",
    "shape_y = 48\n",
    "nClasses = 5"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 25,
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
   "id": "f770e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(shape_x, shape_y, 1))\n",
    "\n",
    "### 1st layer\n",
    "layer_1 = Conv2D(256, (1,1), padding='same', activation='relu')(input_img)\n",
    "layer_1 = Conv2D(256, (3,3), padding='same', activation='relu')(layer_1)\n",
    "layer_1 = BatchNormalization()(layer_1)\n",
<<<<<<< HEAD
    "layer_1 = MaxPooling2D(pool_size=(2,2))(layer_1)\n",
    "layer_1 = Dropout(0.2)(layer_1)\n",
    "\n",
    "layer_2 = Conv2D(128, (3,3), padding='same', activation='relu')(input_img)\n",
    "layer_2 = BatchNormalization()(layer_2)\n",
    "layer_2 = MaxPooling2D(pool_size=(2,2))(layer_2)\n",
    "layer_2 = Dropout(0.2)(layer_2)\n",
    "\n",
    "layer_3 = Conv2D(64, (3,3), padding='same', activation='relu')(input_img)\n",
    "layer_3 = Conv2D(32, (3,3), padding='same', activation='relu')(layer_3)\n",
    "layer_3 = BatchNormalization()(layer_3)\n",
    "layer_3 = MaxPooling2D(pool_size=(2,2))(layer_3)\n",
    "layer_3 = Dropout(0.2)(layer_3)\n",
=======
    "layer_1 = Dropout(0.2)(layer_1)\n",
    "\n",
    "layer_2 = Conv2D(128, (1,1), padding='same', activation='relu')(input_img)\n",
    "layer_2 = Conv2D(64, (5,5), padding='same', activation='relu')(layer_2)\n",
    "layer_2 = BatchNormalization()(layer_2)\n",
    "layer_2 = Dropout(0.2)(layer_2)\n",
    "\n",
    "layer_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
    "layer_3 = Conv2D(32, (1,1), padding='same', activation='relu')(layer_3)\n",
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
    "\n",
    "mid_1 = tensorflow.keras.layers.concatenate([layer_1, layer_2, layer_3], axis = 3)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 26,
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
   "id": "14c7828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flat_1 = Flatten()(mid_1)\n",
<<<<<<< HEAD
    "dense_1 = Dense(64,kernel_initializer = 'he_normal',activation='relu')(flat_1)\n",
    "dense_1 = BatchNormalization()(dense_1)\n",
    "dense_1 = Dropout(0.5)(dense_1)\n",
    "output = Dense(nClasses, activation='softmax')(dense_1)"
=======
    "output = Dense(nClasses, activation='softmax')(flat_1)"
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 27,
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
   "id": "ab8081f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_img], output)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 28,
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
   "id": "e4d38bfb",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint('inception_model.h5',\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)\n",
    "\n",
    "callbacks = [checkpoint]\n"
=======
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 29,
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
   "id": "6e214796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "C:\\Users\\20190\\AppData\\Local\\Temp/ipykernel_19032/1311612697.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
=======
      "C:\\Users\\20190\\AppData\\Local\\Temp/ipykernel_12412/4011575127.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
      "  history=model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 1/25\n",
      "758/759 [============================>.] - ETA: 0s - loss: 1.8145 - accuracy: 0.2477\n",
      "Epoch 00001: val_loss improved from inf to 1.52547, saving model to inception_model.h5\n",
      "759/759 [==============================] - 38s 44ms/step - loss: 1.8142 - accuracy: 0.2477 - val_loss: 1.5255 - val_accuracy: 0.3195\n",
      "Epoch 2/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5810 - accuracy: 0.2790\n",
      "Epoch 00002: val_loss improved from 1.52547 to 1.51854, saving model to inception_model.h5\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5810 - accuracy: 0.2790 - val_loss: 1.5185 - val_accuracy: 0.3226\n",
      "Epoch 3/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5524 - accuracy: 0.3015\n",
      "Epoch 00003: val_loss did not improve from 1.51854\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5524 - accuracy: 0.3015 - val_loss: 1.6562 - val_accuracy: 0.2217\n",
      "Epoch 4/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5481 - accuracy: 0.2999\n",
      "Epoch 00004: val_loss did not improve from 1.51854\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5481 - accuracy: 0.2999 - val_loss: 1.6330 - val_accuracy: 0.2274\n",
      "Epoch 5/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5446 - accuracy: 0.3018\n",
      "Epoch 00005: val_loss did not improve from 1.51854\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5446 - accuracy: 0.3018 - val_loss: 1.6098 - val_accuracy: 0.3044\n",
      "Epoch 6/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5455 - accuracy: 0.3027\n",
      "Epoch 00006: val_loss improved from 1.51854 to 1.51193, saving model to inception_model.h5\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5455 - accuracy: 0.3027 - val_loss: 1.5119 - val_accuracy: 0.3375\n",
      "Epoch 7/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5446 - accuracy: 0.3038\n",
      "Epoch 00007: val_loss did not improve from 1.51193\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5446 - accuracy: 0.3038 - val_loss: 1.5745 - val_accuracy: 0.2887\n",
      "Epoch 8/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5445 - accuracy: 0.3048\n",
      "Epoch 00008: val_loss did not improve from 1.51193\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5445 - accuracy: 0.3048 - val_loss: 1.5328 - val_accuracy: 0.3194\n",
      "Epoch 9/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5396 - accuracy: 0.3065\n",
      "Epoch 00009: val_loss did not improve from 1.51193\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5396 - accuracy: 0.3065 - val_loss: 1.5210 - val_accuracy: 0.3409\n",
      "Epoch 10/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5392 - accuracy: 0.3090\n",
      "Epoch 00010: val_loss did not improve from 1.51193\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5392 - accuracy: 0.3090 - val_loss: 1.5284 - val_accuracy: 0.3227\n",
      "Epoch 11/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5353 - accuracy: 0.3059\n",
      "Epoch 00011: val_loss improved from 1.51193 to 1.50835, saving model to inception_model.h5\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5353 - accuracy: 0.3059 - val_loss: 1.5084 - val_accuracy: 0.3338\n",
      "Epoch 12/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5357 - accuracy: 0.3078\n",
      "Epoch 00012: val_loss did not improve from 1.50835\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5357 - accuracy: 0.3078 - val_loss: 1.6314 - val_accuracy: 0.3327\n",
      "Epoch 13/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5338 - accuracy: 0.3087\n",
      "Epoch 00013: val_loss did not improve from 1.50835\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5338 - accuracy: 0.3087 - val_loss: 1.5900 - val_accuracy: 0.2791\n",
      "Epoch 14/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5284 - accuracy: 0.3128\n",
      "Epoch 00014: val_loss improved from 1.50835 to 1.48424, saving model to inception_model.h5\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5284 - accuracy: 0.3128 - val_loss: 1.4842 - val_accuracy: 0.3483\n",
      "Epoch 15/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5245 - accuracy: 0.3147\n",
      "Epoch 00015: val_loss did not improve from 1.48424\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5245 - accuracy: 0.3147 - val_loss: 1.5364 - val_accuracy: 0.3296\n",
      "Epoch 16/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5210 - accuracy: 0.3167\n",
      "Epoch 00016: val_loss did not improve from 1.48424\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5210 - accuracy: 0.3167 - val_loss: 26.7442 - val_accuracy: 0.2774\n",
      "Epoch 17/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5214 - accuracy: 0.3169\n",
      "Epoch 00017: val_loss improved from 1.48424 to 1.44985, saving model to inception_model.h5\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5214 - accuracy: 0.3169 - val_loss: 1.4498 - val_accuracy: 0.3645\n",
      "Epoch 18/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5098 - accuracy: 0.3256\n",
      "Epoch 00018: val_loss improved from 1.44985 to 1.43475, saving model to inception_model.h5\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5098 - accuracy: 0.3256 - val_loss: 1.4348 - val_accuracy: 0.3726\n",
      "Epoch 19/25\n",
      "758/759 [============================>.] - ETA: 0s - loss: 1.5122 - accuracy: 0.3245\n",
      "Epoch 00019: val_loss did not improve from 1.43475\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5121 - accuracy: 0.3246 - val_loss: 1.4541 - val_accuracy: 0.3701\n",
      "Epoch 20/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5043 - accuracy: 0.3301\n",
      "Epoch 00020: val_loss improved from 1.43475 to 1.43441, saving model to inception_model.h5\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5043 - accuracy: 0.3301 - val_loss: 1.4344 - val_accuracy: 0.3776\n",
      "Epoch 21/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5244 - accuracy: 0.3163\n",
      "Epoch 00021: val_loss did not improve from 1.43441\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5244 - accuracy: 0.3163 - val_loss: 1.4944 - val_accuracy: 0.3495\n",
      "Epoch 22/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5346 - accuracy: 0.3113\n",
      "Epoch 00022: val_loss did not improve from 1.43441\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5346 - accuracy: 0.3113 - val_loss: 1.4917 - val_accuracy: 0.3466\n",
      "Epoch 23/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5300 - accuracy: 0.3119\n",
      "Epoch 00023: val_loss did not improve from 1.43441\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5300 - accuracy: 0.3119 - val_loss: 1.4999 - val_accuracy: 0.3370\n",
      "Epoch 24/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5184 - accuracy: 0.3192\n",
      "Epoch 00024: val_loss did not improve from 1.43441\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5184 - accuracy: 0.3192 - val_loss: 1.4662 - val_accuracy: 0.3630\n",
      "Epoch 25/25\n",
      "759/759 [==============================] - ETA: 0s - loss: 1.5151 - accuracy: 0.3206\n",
      "Epoch 00025: val_loss did not improve from 1.43441\n",
      "759/759 [==============================] - 32s 42ms/step - loss: 1.5151 - accuracy: 0.3206 - val_loss: 2.2860 - val_accuracy: 0.2560\n"
=======
      "Epoch 1/5\n",
      "437/759 [================>.............] - ETA: 16s - loss: 1.8575 - accuracy: 0.2613"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12412/4011575127.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history=model.fit_generator(\n\u001b[0m\u001b[0;32m      2\u001b[0m                 \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 validation_data=validation_generator)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[1;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m         stacklevel=2)\n\u001b[1;32m-> 2016\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   2017\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    548\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \"\"\"\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(\n",
    "                train_generator,\n",
<<<<<<< HEAD
    "                epochs=25,\n",
    "                callbacks=callbacks,\n",
=======
    "                epochs=5,\n",
>>>>>>> 21f64b92dd5e1e09c337a83ce1901df64705330d
    "                validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2997b8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
