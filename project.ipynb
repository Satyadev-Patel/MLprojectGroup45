{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f980cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization,GlobalMaxPooling2D,Activation,MaxPooling2D\n",
    "from tensorflow.nn import local_response_normalization as lrn\n",
    "#create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a230b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(r\"C:\\Users\\20190\\Downloads\\final_train.csv\")\n",
    "X = final_df.drop(columns = ['emotion'])\n",
    "X = X.to_numpy()\n",
    "x_temp = np.reshape(X,(28709,48,48,1))\n",
    "x_temp = x_temp/255\n",
    "\n",
    "y = final_df['emotion']\n",
    "y = y.to_numpy()\n",
    "b = np.zeros((y.size, y.max()+1))\n",
    "b[np.arange(y.size),y] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1538f9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cea9f115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "808/808 [==============================] - 10s 11ms/step - loss: 1.6573 - accuracy: 0.3464 - val_loss: 1.5164 - val_accuracy: 0.4230\n",
      "Epoch 2/10\n",
      "808/808 [==============================] - 9s 11ms/step - loss: 1.4394 - accuracy: 0.4463 - val_loss: 1.4148 - val_accuracy: 0.4554\n",
      "Epoch 3/10\n",
      "808/808 [==============================] - 9s 11ms/step - loss: 1.3046 - accuracy: 0.5059 - val_loss: 1.3577 - val_accuracy: 0.4805\n",
      "Epoch 4/10\n",
      "808/808 [==============================] - 9s 11ms/step - loss: 1.1946 - accuracy: 0.5524 - val_loss: 1.3682 - val_accuracy: 0.4965\n",
      "Epoch 5/10\n",
      "808/808 [==============================] - 9s 11ms/step - loss: 1.0961 - accuracy: 0.5957 - val_loss: 1.3716 - val_accuracy: 0.4976\n",
      "Epoch 6/10\n",
      "808/808 [==============================] - 9s 11ms/step - loss: 1.0051 - accuracy: 0.6297 - val_loss: 1.4245 - val_accuracy: 0.4923\n",
      "Epoch 7/10\n",
      "808/808 [==============================] - 9s 11ms/step - loss: 0.9209 - accuracy: 0.6622 - val_loss: 1.4632 - val_accuracy: 0.4976\n",
      "Epoch 8/10\n",
      "808/808 [==============================] - 9s 11ms/step - loss: 0.8384 - accuracy: 0.6945 - val_loss: 1.5220 - val_accuracy: 0.4913\n",
      "Epoch 9/10\n",
      "808/808 [==============================] - 9s 11ms/step - loss: 0.7616 - accuracy: 0.7244 - val_loss: 1.6287 - val_accuracy: 0.4892\n",
      "Epoch 10/10\n",
      "808/808 [==============================] - 9s 11ms/step - loss: 0.6868 - accuracy: 0.7509 - val_loss: 1.7518 - val_accuracy: 0.4826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x264a86d6940>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=3, activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_temp[2870:],b[2870:],epochs = 10,validation_data = (x_temp[0:2870],b[0:2870]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0446fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24282 images belonging to 5 classes.\n",
      "Found 5937 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "img_rows = 48\n",
    "img_cols = 48\n",
    "batch_size = 32\n",
    "num_classes = 5\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=30,\n",
    "                    shear_range=0.3,\n",
    "                    zoom_range=0.3,\n",
    "                    width_shift_range=0.4,\n",
    "                    height_shift_range=0.4,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_data_dir,\n",
    "                    color_mode='grayscale',\n",
    "                    target_size=(48,48),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical',\n",
    "                    shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                        validation_data_dir,\n",
    "                        color_mode='grayscale',\n",
    "                        target_size=(img_rows,img_cols),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='categorical',\n",
    "                        shuffle=True)\n",
    "\n",
    "\n",
    "nb_train_samples = 24176\n",
    "nb_validation_samples = 3006\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba019e1f",
   "metadata": {},
   "source": [
    "#### USE X_TEMP FOR NEURAL NETWORKS and X for LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50aabd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9ba01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization,GlobalMaxPooling2D,Activation,MaxPooling2D\n",
    "from tensorflow.nn import local_response_normalization as lrn\n",
    "#create model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "85467012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20190\\AppData\\Local\\Temp/ipykernel_3412/970357537.py:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "755/755 [==============================] - 17s 22ms/step - loss: 1.5679 - accuracy: 0.2956 - val_loss: 1.5581 - val_accuracy: 0.3081\n",
      "Epoch 2/10\n",
      "755/755 [==============================] - 16s 21ms/step - loss: 1.5563 - accuracy: 0.2950 - val_loss: 1.5315 - val_accuracy: 0.3118\n",
      "Epoch 3/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5536 - accuracy: 0.2961 - val_loss: 1.5425 - val_accuracy: 0.3101\n",
      "Epoch 4/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5504 - accuracy: 0.2982 - val_loss: 1.5320 - val_accuracy: 0.3017\n",
      "Epoch 5/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5509 - accuracy: 0.2991 - val_loss: 1.5820 - val_accuracy: 0.3058\n",
      "Epoch 6/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5497 - accuracy: 0.2980 - val_loss: 1.5317 - val_accuracy: 0.3182\n",
      "Epoch 7/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5446 - accuracy: 0.2992 - val_loss: 1.5235 - val_accuracy: 0.3229\n",
      "Epoch 8/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5424 - accuracy: 0.3030 - val_loss: 1.5133 - val_accuracy: 0.3310\n",
      "Epoch 9/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5368 - accuracy: 0.3067 - val_loss: 1.4859 - val_accuracy: 0.3498\n",
      "Epoch 10/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5337 - accuracy: 0.3120 - val_loss: 1.4762 - val_accuracy: 0.3595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2651e642460>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=3, activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=nb_train_samples//batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79adf43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f1308b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20190\\AppData\\Local\\Temp/ipykernel_3412/3575998937.py:18: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755/755 [==============================] - 17s 21ms/step - loss: 1.5709 - accuracy: 0.2927 - val_loss: 1.5583 - val_accuracy: 0.3058\n",
      "Epoch 2/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5580 - accuracy: 0.2949 - val_loss: 1.5619 - val_accuracy: 0.3108\n",
      "Epoch 3/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5551 - accuracy: 0.2972 - val_loss: 1.5578 - val_accuracy: 0.3068\n",
      "Epoch 4/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5500 - accuracy: 0.3005 - val_loss: 1.5565 - val_accuracy: 0.2970\n",
      "Epoch 5/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5452 - accuracy: 0.3016 - val_loss: 1.5483 - val_accuracy: 0.2977\n",
      "Epoch 6/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5397 - accuracy: 0.3071 - val_loss: 1.5251 - val_accuracy: 0.3162\n",
      "Epoch 7/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5345 - accuracy: 0.3094 - val_loss: 1.5230 - val_accuracy: 0.3091\n",
      "Epoch 8/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5263 - accuracy: 0.3175 - val_loss: 1.4963 - val_accuracy: 0.3320\n",
      "Epoch 9/10\n",
      "755/755 [==============================] - 16s 21ms/step - loss: 1.5190 - accuracy: 0.3214 - val_loss: 1.5017 - val_accuracy: 0.3276\n",
      "Epoch 10/10\n",
      "755/755 [==============================] - 16s 21ms/step - loss: 1.5143 - accuracy: 0.3227 - val_loss: 1.4774 - val_accuracy: 0.3417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26526c92550>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=3, activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=nb_train_samples//batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80ef71f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20190\\AppData\\Local\\Temp/ipykernel_3412/469966306.py:17: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755/755 [==============================] - 17s 21ms/step - loss: 1.5735 - accuracy: 0.2850 - val_loss: 1.7179 - val_accuracy: 0.1966\n",
      "Epoch 2/10\n",
      "755/755 [==============================] - 16s 21ms/step - loss: 1.5558 - accuracy: 0.2942 - val_loss: 1.5611 - val_accuracy: 0.3098\n",
      "Epoch 3/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5529 - accuracy: 0.2951 - val_loss: 1.5486 - val_accuracy: 0.3229\n",
      "Epoch 4/10\n",
      "755/755 [==============================] - 16s 21ms/step - loss: 1.5455 - accuracy: 0.3036 - val_loss: 1.7717 - val_accuracy: 0.2755\n",
      "Epoch 5/10\n",
      "755/755 [==============================] - 17s 23ms/step - loss: 1.5342 - accuracy: 0.3094 - val_loss: 1.4770 - val_accuracy: 0.3525\n",
      "Epoch 6/10\n",
      "755/755 [==============================] - 17s 23ms/step - loss: 1.5174 - accuracy: 0.3224 - val_loss: 1.6060 - val_accuracy: 0.2739\n",
      "Epoch 7/10\n",
      "755/755 [==============================] - 16s 21ms/step - loss: 1.4942 - accuracy: 0.3368 - val_loss: 1.6760 - val_accuracy: 0.2272\n",
      "Epoch 8/10\n",
      "755/755 [==============================] - 16s 21ms/step - loss: 1.4676 - accuracy: 0.3488 - val_loss: 1.4512 - val_accuracy: 0.3239\n",
      "Epoch 9/10\n",
      "755/755 [==============================] - 16s 21ms/step - loss: 1.4421 - accuracy: 0.3667 - val_loss: 1.7114 - val_accuracy: 0.2382\n",
      "Epoch 10/10\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.4259 - accuracy: 0.3784 - val_loss: 1.3548 - val_accuracy: 0.4264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x264a88f3c10>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=3, activation='relu', input_shape=(48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=nb_train_samples//batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2706504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20190\\AppData\\Local\\Temp/ipykernel_3412/3609173775.py:23: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755/755 [==============================] - 35s 46ms/step - loss: 1.5771 - accuracy: 0.2927 - val_loss: 1.5790 - val_accuracy: 0.3071\n",
      "Epoch 2/10\n",
      "755/755 [==============================] - 33s 44ms/step - loss: 1.5686 - accuracy: 0.2918 - val_loss: 1.5376 - val_accuracy: 0.3101\n",
      "Epoch 3/10\n",
      "755/755 [==============================] - 33s 44ms/step - loss: 1.5761 - accuracy: 0.2956 - val_loss: 1.5773 - val_accuracy: 0.2994\n",
      "Epoch 4/10\n",
      "755/755 [==============================] - 33s 44ms/step - loss: 1.5764 - accuracy: 0.2947 - val_loss: 1.5740 - val_accuracy: 0.3058\n",
      "Epoch 5/10\n",
      "755/755 [==============================] - 33s 44ms/step - loss: 1.5763 - accuracy: 0.2947 - val_loss: 1.5756 - val_accuracy: 0.3054\n",
      "Epoch 6/10\n",
      "755/755 [==============================] - 33s 44ms/step - loss: 1.5766 - accuracy: 0.2946 - val_loss: 1.5692 - val_accuracy: 0.3088\n",
      "Epoch 7/10\n",
      "755/755 [==============================] - 34s 45ms/step - loss: 1.5761 - accuracy: 0.2948 - val_loss: 1.5753 - val_accuracy: 0.3004\n",
      "Epoch 8/10\n",
      "755/755 [==============================] - 34s 45ms/step - loss: 1.5759 - accuracy: 0.2954 - val_loss: 1.5695 - val_accuracy: 0.3088\n",
      "Epoch 9/10\n",
      "755/755 [==============================] - 34s 45ms/step - loss: 1.5753 - accuracy: 0.2950 - val_loss: 1.5736 - val_accuracy: 0.3088\n",
      "Epoch 10/10\n",
      "755/755 [==============================] - 34s 44ms/step - loss: 1.5760 - accuracy: 0.2947 - val_loss: 1.5705 - val_accuracy: 0.3001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x264acc7a550>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=3,padding='same', activation='relu', input_shape=(48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(256, kernel_size=3, padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, kernel_size=3, padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, kernel_size=3, padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same',activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=nb_train_samples//batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01ac001d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24282 images belonging to 5 classes.\n",
      "Found 5937 images belonging to 5 classes.\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_192 (Conv2D)         (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " activation_123 (Activation)  (None, 48, 48, 32)       0         \n",
      "                                                                 \n",
      " batch_normalization_128 (Ba  (None, 48, 48, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_193 (Conv2D)         (None, 48, 48, 32)        9248      \n",
      "                                                                 \n",
      " activation_124 (Activation)  (None, 48, 48, 32)       0         \n",
      "                                                                 \n",
      " batch_normalization_129 (Ba  (None, 48, 48, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_100 (MaxPooli  (None, 24, 24, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_194 (Conv2D)         (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " activation_125 (Activation)  (None, 24, 24, 64)       0         \n",
      "                                                                 \n",
      " batch_normalization_130 (Ba  (None, 24, 24, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_195 (Conv2D)         (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " activation_126 (Activation)  (None, 24, 24, 64)       0         \n",
      "                                                                 \n",
      " batch_normalization_131 (Ba  (None, 24, 24, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_101 (MaxPooli  (None, 12, 12, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " conv2d_196 (Conv2D)         (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " activation_127 (Activation)  (None, 12, 12, 128)      0         \n",
      "                                                                 \n",
      " batch_normalization_132 (Ba  (None, 12, 12, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_197 (Conv2D)         (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " activation_128 (Activation)  (None, 12, 12, 128)      0         \n",
      "                                                                 \n",
      " batch_normalization_133 (Ba  (None, 12, 12, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_102 (MaxPooli  (None, 6, 6, 128)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " conv2d_198 (Conv2D)         (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " activation_129 (Activation)  (None, 6, 6, 256)        0         \n",
      "                                                                 \n",
      " batch_normalization_134 (Ba  (None, 6, 6, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_199 (Conv2D)         (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " activation_130 (Activation)  (None, 6, 6, 256)        0         \n",
      "                                                                 \n",
      " batch_normalization_135 (Ba  (None, 6, 6, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_103 (MaxPooli  (None, 3, 3, 256)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 64)                147520    \n",
      "                                                                 \n",
      " activation_131 (Activation)  (None, 64)               0         \n",
      "                                                                 \n",
      " batch_normalization_136 (Ba  (None, 64)               256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " activation_132 (Activation)  (None, 64)               0         \n",
      "                                                                 \n",
      " batch_normalization_137 (Ba  (None, 64)               256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      " activation_133 (Activation)  (None, 5)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,328,037\n",
      "Trainable params: 1,325,861\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20190\\AppData\\Local\\Temp/ipykernel_3412/1054553554.py:116: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history=model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755/755 [==============================] - 16s 20ms/step - loss: 1.8260 - accuracy: 0.2376 - val_loss: 1.5336 - val_accuracy: 0.3081\n",
      "Epoch 2/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.5763 - accuracy: 0.2773 - val_loss: 1.5231 - val_accuracy: 0.3219\n",
      "Epoch 3/25\n",
      "755/755 [==============================] - 15s 19ms/step - loss: 1.5525 - accuracy: 0.2988 - val_loss: 1.4911 - val_accuracy: 0.3407\n",
      "Epoch 4/25\n",
      "755/755 [==============================] - 14s 19ms/step - loss: 1.5227 - accuracy: 0.3159 - val_loss: 1.4516 - val_accuracy: 0.3233\n",
      "Epoch 5/25\n",
      "755/755 [==============================] - 15s 19ms/step - loss: 1.4648 - accuracy: 0.3585 - val_loss: 1.3899 - val_accuracy: 0.4311\n",
      "Epoch 6/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.3726 - accuracy: 0.4209 - val_loss: 1.1137 - val_accuracy: 0.5585\n",
      "Epoch 7/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.2862 - accuracy: 0.4697 - val_loss: 1.0237 - val_accuracy: 0.5837\n",
      "Epoch 8/25\n",
      "755/755 [==============================] - 14s 19ms/step - loss: 1.2265 - accuracy: 0.5002 - val_loss: 0.9782 - val_accuracy: 0.6089\n",
      "Epoch 9/25\n",
      "755/755 [==============================] - 14s 19ms/step - loss: 1.1912 - accuracy: 0.5115 - val_loss: 0.9808 - val_accuracy: 0.6058\n",
      "Epoch 10/25\n",
      "755/755 [==============================] - 14s 19ms/step - loss: 1.1670 - accuracy: 0.5302 - val_loss: 0.9038 - val_accuracy: 0.6415\n",
      "Epoch 11/25\n",
      "755/755 [==============================] - 14s 19ms/step - loss: 1.1372 - accuracy: 0.5433 - val_loss: 0.8815 - val_accuracy: 0.6475\n",
      "Epoch 12/25\n",
      "755/755 [==============================] - 15s 19ms/step - loss: 1.1132 - accuracy: 0.5527 - val_loss: 0.8686 - val_accuracy: 0.6626\n",
      "Epoch 13/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.0945 - accuracy: 0.5660 - val_loss: 0.8486 - val_accuracy: 0.6623\n",
      "Epoch 14/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.0865 - accuracy: 0.5725 - val_loss: 0.8645 - val_accuracy: 0.6720\n",
      "Epoch 15/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.0655 - accuracy: 0.5833 - val_loss: 0.8342 - val_accuracy: 0.6754\n",
      "Epoch 16/25\n",
      "755/755 [==============================] - 15s 19ms/step - loss: 1.0551 - accuracy: 0.5886 - val_loss: 0.8482 - val_accuracy: 0.6767\n",
      "Epoch 17/25\n",
      "755/755 [==============================] - 14s 19ms/step - loss: 1.0517 - accuracy: 0.5897 - val_loss: 0.7989 - val_accuracy: 0.6915\n",
      "Epoch 18/25\n",
      "755/755 [==============================] - 15s 19ms/step - loss: 1.0330 - accuracy: 0.5982 - val_loss: 0.7806 - val_accuracy: 0.7063\n",
      "Epoch 19/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.0307 - accuracy: 0.6012 - val_loss: 0.7971 - val_accuracy: 0.6929\n",
      "Epoch 20/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.0205 - accuracy: 0.6035 - val_loss: 0.8160 - val_accuracy: 0.6865\n",
      "Epoch 21/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.0050 - accuracy: 0.6105 - val_loss: 0.8087 - val_accuracy: 0.6899\n",
      "Epoch 22/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 1.0009 - accuracy: 0.6122 - val_loss: 0.7535 - val_accuracy: 0.7083\n",
      "Epoch 23/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 0.9952 - accuracy: 0.6158 - val_loss: 0.7819 - val_accuracy: 0.6952\n",
      "Epoch 24/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 0.9916 - accuracy: 0.6187 - val_loss: 0.7699 - val_accuracy: 0.6999\n",
      "Epoch 25/25\n",
      "755/755 [==============================] - 15s 20ms/step - loss: 0.9863 - accuracy: 0.6221 - val_loss: 0.8075 - val_accuracy: 0.6845\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "img_rows = 48\n",
    "img_cols = 48\n",
    "batch_size = 32\n",
    "num_classes = 5\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=30,\n",
    "                shear_range=0.3,\n",
    "                zoom_range=0.3,\n",
    "                width_shift_range=0.4,\n",
    "                height_shift_range=0.4,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_data_dir,\n",
    "                color_mode='grayscale',\n",
    "                target_size=(48,48),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical',\n",
    "                shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                        validation_data_dir,\n",
    "                        color_mode='grayscale',\n",
    "                        target_size=(img_rows,img_cols),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='categorical',\n",
    "                        shuffle=True)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Block-1\n",
    "\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-2 \n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-3\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-4 \n",
    "\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-5\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block-6\n",
    "\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block-7\n",
    "\n",
    "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nb_train_samples = 24176\n",
    "nb_validation_samples = 3006\n",
    "epochs=25\n",
    "\n",
    "history=model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=nb_train_samples//batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=nb_validation_samples//batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd2a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf3a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de506964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e14943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0b5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfbc41b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
